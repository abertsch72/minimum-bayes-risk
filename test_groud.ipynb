{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3b2768bf9bd6425acc869120a7136bda7c2db4d32a4c0d82d14afba9d9f0b9d5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\n",
    "\n",
    "text = [' annual', ' European', ' AC', ' 2018', ' Conference', ' International', ' Neural', ' American', ' conference', ' National']\n",
    "for t in text:\n",
    "    doc = nlp(t.strip())\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "                token.shape_, token.is_alpha, token.is_stop)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "annual annual ADJ JJ ROOT xxxx True False\n",
      "European european ADJ JJ ROOT Xxxxx True False\n",
      "AC AC PROPN NNP ROOT XX True False\n",
      "2018 2018 NUM CD ROOT dddd False False\n",
      "Conference conference NOUN NN ROOT Xxxxx True False\n",
      "International international ADJ JJ ROOT Xxxxx True False\n",
      "Neural neural ADJ JJ ROOT Xxxxx True False\n",
      "American American PROPN NNP ROOT Xxxxx True False\n",
      "conference conference NOUN NN ROOT xxxx True False\n",
      "National national ADJ JJ ROOT Xxxxx True False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-xsum')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-xsum')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ARTICLE_TO_SUMMARIZE = \"The Bart model was proposed in BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer on 29 Oct, 2019. According to the abstract, Bart uses a standard seq2seq/machine translation architecture with a bidirectional encoder (like BERT) and a left-to-right decoder (like GPT). The pretraining task involves randomly shuffling the order of the original sentences and a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD, achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 6 ROUGE.\"\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n",
    "# Generate Summary\n",
    "BG=[2,5]\n",
    "beam_size = [ 100]\n",
    "for group_num in BG:\n",
    "    for bs in beam_size:\n",
    "        if bs <= group_num:\n",
    "            continue\n",
    "        print(\"-\"*30)\n",
    "        print(f\"Beam Size:{bs}\\tDiverse Beam Group #:{group_num}\")\n",
    "        summary_ids = model.generate(inputs['input_ids'], num_beams=bs, max_length=30, early_stopping=True,num_return_sequences=10,num_beam_groups=group_num)\n",
    "        print(\"\\n\".join([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------\n",
      "Beam Size:100\tDiverse Beam Group #:2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}